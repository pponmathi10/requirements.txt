# -*- coding: utf-8 -*-
"""project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GeafcE9qUlPpjzLQMRH8IOunRC9cEUAn
"""
streamlit
pandas
scikit-learn
joblib
numpy
git add requirements.txt
git commit -m "Added requirements"
git push
import streamlit as st
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import PyPDF2
import re

# Page Configuration
st.set_page_config(page_title="AI Resume Screener", layout="wide")

def clean_text(text):
    text = re.sub(r'\s+', ' ', text)  # Remove extra whitespace
    text = re.sub(r'[^a-zA-Z0-9\s]', '', text)  # Remove special characters
    return text.lower()

def extract_text(file):
    try:
        pdf_reader = PyPDF2.PdfReader(file)
        return " ".join([page.extract_text() for page in pdf_reader.pages if page.extract_text()])
    except Exception as e:
        return ""

# UI Layout
st.title("ðŸ¤– Intelligent Resume Screening System")
st.markdown("Rank resumes based on Job Description similarity using NLP.")

col1, col2 = st.columns(2)

with col1:
    jd = st.text_area("Step 1: Paste Job Description", height=300)

with col2:
    uploaded_files = st.file_uploader("Step 2: Upload Resumes (PDF)", type="pdf", accept_multiple_files=True)

if st.button("Analyze & Rank"):
    if jd and uploaded_files:
        with st.spinner('Analyzing...'):
            # Process JD
            cleaned_jd = clean_text(jd)
            
            # Process Resumes
            resumes = []
            filenames = []
            for file in uploaded_files:
                text = extract_text(file)
                if text:
                    resumes.append(clean_text(text))
                    filenames.append(file.name)
            
            if resumes:
                # ML Pipeline: TF-IDF
                vectorizer = TfidfVectorizer(stop_words='english')
                all_texts = [cleaned_jd] + resumes
                tfidf_matrix = vectorizer.fit_transform(all_texts)
                
                # Similarity Calculation
                match_percentage = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:]).flatten()
                
                # Results Table
                results = pd.DataFrame({
                    "Candidate Name": filenames,
                    "Match Score (%)": [round(s * 100, 2) for s in match_percentage]
                }).sort_values(by="Match Score (%)", ascending=False)
                
                st.success("Analysis Complete!")
                st.table(results)
            else:
                st.error("Could not extract text from the uploaded PDFs.")
    else:
        st.warning("Please provide both a Job Description and Resumes.")
